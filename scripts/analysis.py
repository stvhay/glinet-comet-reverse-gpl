#!/usr/bin/env python3
"""
Analysis framework for Jinja template-based documentation.

This module provides hash-based caching of analysis results with automatic
invalidation when firmware or analysis scripts change.

It also provides TrackedValue for automatic source attribution and footnoting.
"""

from functools import lru_cache
from pathlib import Path
from contextlib import contextmanager
import subprocess
import json
import hashlib
import tomlkit
from datetime import datetime
import tempfile
import os
from typing import Any, Optional


class TrackedValue:
    """
    A value with source attribution for automatic footnoting.

    Attributes:
        value: The actual value (offset, size, string, etc.)
        source: Source script name (e.g., "analyze_kernel")
        method: Discovery method (e.g., "binwalk -e firmware.img | grep kernel")
    """

    def __init__(self, value: Any, source: str, method: Optional[str] = None):
        self.value = value
        self.source = source
        self.method = method

    def __str__(self):
        """Return string representation of value."""
        return str(self.value)

    def __repr__(self):
        """Return detailed representation."""
        return f"TrackedValue({self.value!r}, source={self.source!r}, method={self.method!r})"

    # Support common operations on the wrapped value
    def __eq__(self, other):
        if isinstance(other, TrackedValue):
            return self.value == other.value
        return self.value == other

    def __int__(self):
        return int(self.value)

    def __float__(self):
        return float(self.value)


@lru_cache(maxsize=None)
def analyze(analysis_type: str) -> dict:
    """
    Main function called from Jinja templates.

    Uses two-tier caching:
    - Memory: @lru_cache prevents re-running during single render pass
    - Disk: results/*.toml persists across runs with hash-based invalidation

    Args:
        analysis_type: Name of analysis (e.g., 'kernel', 'filesystem')

    Returns:
        Dictionary of analysis results, with values wrapped as TrackedValue
        when they include _source metadata
    """
    results_file = Path(f'results/{analysis_type}.toml')
    manifest_file = Path('results/.manifest.toml')

    # Check if cache is valid
    if is_cache_valid(analysis_type, manifest_file):
        result = dict(tomlkit.load(results_file.open()))
        return convert_to_tracked_values(result, analysis_type)

    # Run analysis
    result = run_analysis(analysis_type)

    # Save results with comments (flatten TrackedValues for storage)
    results_file.parent.mkdir(exist_ok=True)
    with atomic_write(results_file) as f:
        doc = tomlkit.document()
        doc.add(tomlkit.comment(f"Generated by analyze_{analysis_type}"))
        doc.add(tomlkit.comment(f"Timestamp: {datetime.now().isoformat()}"))
        doc.add(tomlkit.nl())

        for key, value in result.items():
            doc[key] = value

        tomlkit.dump(doc, f)

    # Update manifest
    update_manifest(analysis_type, manifest_file)

    return convert_to_tracked_values(result, analysis_type)


def convert_to_tracked_values(result: dict, analysis_type: str) -> dict:
    """
    Convert result dictionary to use TrackedValue objects.

    If a key has a corresponding {key}_source and/or {key}_method,
    wrap the value as TrackedValue with that metadata.
    """
    tracked_result = {}

    for key, value in result.items():
        # Skip metadata keys
        if key.endswith('_source') or key.endswith('_method'):
            continue

        # Check for source/method metadata
        source = result.get(f'{key}_source', analysis_type)
        method = result.get(f'{key}_method')

        # If we have source/method metadata, create TrackedValue
        if f'{key}_source' in result or f'{key}_method' in result:
            tracked_result[key] = TrackedValue(value, source, method)
        else:
            # Plain value (backward compatible)
            tracked_result[key] = value

    return tracked_result


def is_cache_valid(analysis_type: str, manifest_file: Path) -> bool:
    """
    Check if cached results are still valid.

    Cache is valid if:
    - Results file exists
    - Manifest exists with entry for this analysis
    - Firmware hash matches
    - Script hash matches
    """
    results_file = Path(f'results/{analysis_type}.toml')

    if not results_file.exists() or not manifest_file.exists():
        return False

    manifest = tomlkit.load(manifest_file.open())
    if analysis_type not in manifest:
        return False

    # Calculate current hashes
    current_fw_hash = hash_firmware()
    current_script_hash = hash_analysis_script(analysis_type)

    # Compare with manifest
    cached = manifest[analysis_type]
    return (cached.get('firmware_hash') == current_fw_hash and
            cached.get('script_hash') == current_script_hash)


def update_manifest(analysis_type: str, manifest_file: Path) -> None:
    """Update manifest with current hashes."""
    if manifest_file.exists():
        manifest = tomlkit.load(manifest_file.open())
    else:
        manifest = tomlkit.document()
        manifest.add(tomlkit.comment("Analysis results manifest"))
        manifest.add(tomlkit.comment("Tracks firmware and script hashes for cache invalidation"))
        manifest.add(tomlkit.nl())

    manifest[analysis_type] = {
        'firmware_hash': hash_firmware(),
        'script_hash': hash_analysis_script(analysis_type),
        'last_updated': datetime.now().isoformat()
    }

    with atomic_write(manifest_file) as f:
        tomlkit.dump(manifest, f)


def run_analysis(analysis_type: str) -> dict:
    """
    Execute analysis script and parse JSON output.

    Tries bash script first (for backward compatibility during migration),
    then falls back to Python script.
    """
    # Try bash script first (during transition period)
    bash_script = Path(f'scripts/analyze_{analysis_type}.sh')
    if bash_script.exists():
        output = subprocess.check_output(
            [bash_script],
            text=True,
            cwd=Path.cwd()
        )
        return json.loads(output)

    # Try Python version
    py_script = Path(f'scripts/analyze_{analysis_type}.py')
    if py_script.exists():
        # Import and call Python function
        import importlib.util
        spec = importlib.util.spec_from_file_location(analysis_type, py_script)
        module = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(module)
        return module.analyze()

    raise FileNotFoundError(
        f"No analysis script found for '{analysis_type}'. "
        f"Expected: scripts/analyze_{analysis_type}.sh or .py"
    )


def hash_firmware() -> str:
    """
    Calculate hash of firmware file.

    For POC, uses a dummy file if firmware doesn't exist yet.
    """
    firmware_path = Path('downloads/firmware.img')

    # For POC: if firmware doesn't exist, return a placeholder
    if not firmware_path.exists():
        return "no-firmware-yet"

    return hash_file(firmware_path)


def hash_analysis_script(analysis_type: str) -> str:
    """Calculate hash of analysis script (bash or python)."""
    for ext in ['.sh', '.py']:
        script = Path(f'scripts/analyze_{analysis_type}{ext}')
        if script.exists():
            return hash_file(script)
    return "unknown"


def hash_file(filepath: Path) -> str:
    """
    Calculate SHA256 hash of file.

    Returns first 16 characters for brevity.
    """
    sha256 = hashlib.sha256()
    with open(filepath, 'rb') as f:
        for chunk in iter(lambda: f.read(8192), b''):
            sha256.update(chunk)
    return sha256.hexdigest()[:16]


@contextmanager
def atomic_write(filepath: Path):  # type: ignore[misc]
    """
    Context manager for atomic file writes.

    Writes to temporary file, then atomically renames to target.
    This prevents race conditions and partial writes.
    """
    filepath.parent.mkdir(parents=True, exist_ok=True)

    # Create temp file in same directory (required for atomic rename)
    tmp_fd, tmp_path = tempfile.mkstemp(
        dir=filepath.parent,
        prefix=f'.{filepath.name}.',
        suffix='.tmp'
    )

    try:
        with os.fdopen(tmp_fd, 'w') as f:
            yield f
        # Atomic rename (on POSIX systems)
        os.rename(tmp_path, filepath)
    except Exception:
        # Clean up temp file on error
        try:
            os.unlink(tmp_path)
        except OSError:
            pass
        raise


if __name__ == '__main__':
    # Simple test
    print("Analysis framework loaded successfully")
    print(f"Firmware hash: {hash_firmware()}")
